{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPXFUumO89hXj6Q0Att/Tuk",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krishnaKalyan553/demo/blob/main/Untitled2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbJIam2Y-xuv"
      },
      "source": [
        "from zipfile import ZipFile\n",
        "import numpy as np\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Reshape\n",
        "from keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import os \n",
        "import cv2\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "#from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.preprocessing.image import ImageDataGenerator "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIryGFsDWDoY",
        "outputId": "7c6ee6cd-7676-440b-ebe3-8591473cacdf"
      },
      "source": [
        "file=[\"brother.zip\",\"father.zip\",\"mother.zip\",\"sister.zip\"]\n",
        "for file_name in file:\n",
        "  with  ZipFile(file_name, 'r') as zip:\n",
        "    print('Extracting all the files now...')\n",
        "    zip.extractall()\n",
        "    print('Done!')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Extracting all the files now...\n",
            "Done!\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "Extracting all the files now...\n",
            "Done!\n",
            "Extracting all the files now...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UZe_2pPi6iMq"
      },
      "source": [
        "x=[]\n",
        "y=[]\n",
        "mapping={\n",
        "    \"brother\":0,\n",
        "    \"father\":1,\n",
        "    \"mother\":2,\n",
        "    \"sister\":3,\n",
        "    }\n",
        "path=\"/content\"\n",
        "for relate in mapping.keys():\n",
        "  for img in os.listdir(os.path.join(path,relate)):\n",
        "    im=cv2.imread(os.path.join(path,relate,img))\n",
        "    im=cv2.cvtColor(im,cv2.COLOR_BGR2GRAY)\n",
        "    im=cv2.resize(im,(30,30))\n",
        "    x.append(im)\n",
        "    y.append(mapping[relate])\n",
        "x=np.array(x)\n",
        "y=np.array(y)\n",
        "x=x.reshape(x.shape[0],30,30,1)\n",
        "x=x.astype('float32')\n",
        "x=x/255\n",
        "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n",
        "x_train,x_valid,y_train,y_valid=train_test_split(x_train,y_train,test_size=0.2)\n",
        "early_stopping=EarlyStopping(\n",
        "    min_delta=0.001,\n",
        "    patience=5, \n",
        "    restore_best_weights=True,\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8ZTCUQLHFDVt",
        "outputId": "176aafba-ebea-4313-eb49-b5112a08a65c"
      },
      "source": [
        "model=Sequential()\n",
        "model.add(Conv2D(filters=12,kernel_size=2,strides=(1,1),padding=\"valid\",input_shape=(30,30,1),activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(.4))\n",
        "model.add(Conv2D(filters=10,kernel_size=3,strides=(1,1),padding=\"same\",activation=\"relu\"))\n",
        "model.add(MaxPool2D(pool_size=(2,2)))\n",
        "model.add(layers.BatchNormalization())\n",
        "model.add(layers.Dropout(.3))\n",
        "# model.add(Conv2D(filters=10,kernel_size=2,strides=(1,1),padding=\"valid\",activation=\"relu\"))\n",
        "# model.add(layers.AveragePooling2D(pool_size=(2,2)))\n",
        "# model.add(layers.BatchNormalization())\n",
        "# model.add(layers.Dropout(.2))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(4,activation=\"softmax\"))\n",
        "model.summary()\n",
        "model.compile(loss=\"sparse_categorical_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])\n",
        "model.fit(x_train,y_train,epochs=200,callbacks=[early_stopping],validation_data=(x_valid, y_valid))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_3\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_9 (Conv2D)            (None, 29, 29, 12)        60        \n",
            "_________________________________________________________________\n",
            "max_pooling2d_6 (MaxPooling2 (None, 14, 14, 12)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 14, 14, 12)        48        \n",
            "_________________________________________________________________\n",
            "dropout_9 (Dropout)          (None, 14, 14, 12)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_10 (Conv2D)           (None, 14, 14, 10)        1090      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_10 (Batc (None, 7, 7, 10)          40        \n",
            "_________________________________________________________________\n",
            "dropout_10 (Dropout)         (None, 7, 7, 10)          0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 490)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 4)                 1964      \n",
            "=================================================================\n",
            "Total params: 3,202\n",
            "Trainable params: 3,158\n",
            "Non-trainable params: 44\n",
            "_________________________________________________________________\n",
            "Epoch 1/200\n",
            "16/16 [==============================] - 2s 51ms/step - loss: 2.0808 - accuracy: 0.2472 - val_loss: 1.3743 - val_accuracy: 0.2891\n",
            "Epoch 2/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.4554 - accuracy: 0.4042 - val_loss: 1.3626 - val_accuracy: 0.3672\n",
            "Epoch 3/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 1.0690 - accuracy: 0.5879 - val_loss: 1.3588 - val_accuracy: 0.4141\n",
            "Epoch 4/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.8929 - accuracy: 0.6403 - val_loss: 1.3703 - val_accuracy: 0.3750\n",
            "Epoch 5/200\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.8223 - accuracy: 0.6909 - val_loss: 1.3669 - val_accuracy: 0.3203\n",
            "Epoch 6/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.7161 - accuracy: 0.7501 - val_loss: 1.3433 - val_accuracy: 0.3906\n",
            "Epoch 7/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.6683 - accuracy: 0.7106 - val_loss: 1.3211 - val_accuracy: 0.3594\n",
            "Epoch 8/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.5913 - accuracy: 0.7874 - val_loss: 1.3100 - val_accuracy: 0.3906\n",
            "Epoch 9/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.5680 - accuracy: 0.8016 - val_loss: 1.2569 - val_accuracy: 0.5156\n",
            "Epoch 10/200\n",
            "16/16 [==============================] - 0s 22ms/step - loss: 0.4959 - accuracy: 0.8009 - val_loss: 1.2184 - val_accuracy: 0.5703\n",
            "Epoch 11/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4854 - accuracy: 0.8119 - val_loss: 1.1771 - val_accuracy: 0.5938\n",
            "Epoch 12/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.4050 - accuracy: 0.8552 - val_loss: 1.1476 - val_accuracy: 0.6016\n",
            "Epoch 13/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.4561 - accuracy: 0.8312 - val_loss: 1.1106 - val_accuracy: 0.5938\n",
            "Epoch 14/200\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.4228 - accuracy: 0.8698 - val_loss: 1.0727 - val_accuracy: 0.6172\n",
            "Epoch 15/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.3447 - accuracy: 0.8854 - val_loss: 1.0029 - val_accuracy: 0.6250\n",
            "Epoch 16/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3710 - accuracy: 0.8704 - val_loss: 0.9700 - val_accuracy: 0.6406\n",
            "Epoch 17/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.3743 - accuracy: 0.8697 - val_loss: 0.9004 - val_accuracy: 0.6484\n",
            "Epoch 18/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2961 - accuracy: 0.8790 - val_loss: 0.9186 - val_accuracy: 0.6562\n",
            "Epoch 19/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.3482 - accuracy: 0.8908 - val_loss: 0.8353 - val_accuracy: 0.6875\n",
            "Epoch 20/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2927 - accuracy: 0.8942 - val_loss: 0.7832 - val_accuracy: 0.7266\n",
            "Epoch 21/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.3392 - accuracy: 0.8838 - val_loss: 0.6919 - val_accuracy: 0.7812\n",
            "Epoch 22/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2769 - accuracy: 0.8934 - val_loss: 0.6709 - val_accuracy: 0.7812\n",
            "Epoch 23/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2622 - accuracy: 0.9123 - val_loss: 0.6323 - val_accuracy: 0.7812\n",
            "Epoch 24/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2809 - accuracy: 0.8973 - val_loss: 0.5651 - val_accuracy: 0.7969\n",
            "Epoch 25/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2134 - accuracy: 0.9261 - val_loss: 0.5470 - val_accuracy: 0.8047\n",
            "Epoch 26/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2461 - accuracy: 0.8992 - val_loss: 0.5139 - val_accuracy: 0.8203\n",
            "Epoch 27/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2470 - accuracy: 0.8908 - val_loss: 0.5140 - val_accuracy: 0.8438\n",
            "Epoch 28/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.2468 - accuracy: 0.9137 - val_loss: 0.4749 - val_accuracy: 0.8203\n",
            "Epoch 29/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1903 - accuracy: 0.9310 - val_loss: 0.4182 - val_accuracy: 0.8672\n",
            "Epoch 30/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1851 - accuracy: 0.9389 - val_loss: 0.4263 - val_accuracy: 0.8750\n",
            "Epoch 31/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1783 - accuracy: 0.9274 - val_loss: 0.3937 - val_accuracy: 0.9062\n",
            "Epoch 32/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1827 - accuracy: 0.9373 - val_loss: 0.3820 - val_accuracy: 0.9062\n",
            "Epoch 33/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1656 - accuracy: 0.9413 - val_loss: 0.3488 - val_accuracy: 0.9375\n",
            "Epoch 34/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1742 - accuracy: 0.9431 - val_loss: 0.3264 - val_accuracy: 0.9375\n",
            "Epoch 35/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1771 - accuracy: 0.9420 - val_loss: 0.3141 - val_accuracy: 0.9453\n",
            "Epoch 36/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1943 - accuracy: 0.9321 - val_loss: 0.3119 - val_accuracy: 0.9531\n",
            "Epoch 37/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.2171 - accuracy: 0.9032 - val_loss: 0.2857 - val_accuracy: 0.9531\n",
            "Epoch 38/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1679 - accuracy: 0.9417 - val_loss: 0.2812 - val_accuracy: 0.9531\n",
            "Epoch 39/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1504 - accuracy: 0.9622 - val_loss: 0.2674 - val_accuracy: 0.9531\n",
            "Epoch 40/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1958 - accuracy: 0.9418 - val_loss: 0.2558 - val_accuracy: 0.9609\n",
            "Epoch 41/200\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1349 - accuracy: 0.9602 - val_loss: 0.2464 - val_accuracy: 0.9609\n",
            "Epoch 42/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1294 - accuracy: 0.9586 - val_loss: 0.2568 - val_accuracy: 0.9609\n",
            "Epoch 43/200\n",
            "16/16 [==============================] - 0s 25ms/step - loss: 0.1581 - accuracy: 0.9419 - val_loss: 0.2505 - val_accuracy: 0.9531\n",
            "Epoch 44/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1618 - accuracy: 0.9532 - val_loss: 0.2472 - val_accuracy: 0.9531\n",
            "Epoch 45/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1188 - accuracy: 0.9657 - val_loss: 0.2416 - val_accuracy: 0.9531\n",
            "Epoch 46/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1704 - accuracy: 0.9466 - val_loss: 0.2340 - val_accuracy: 0.9531\n",
            "Epoch 47/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1550 - accuracy: 0.9432 - val_loss: 0.2425 - val_accuracy: 0.9531\n",
            "Epoch 48/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1169 - accuracy: 0.9647 - val_loss: 0.2516 - val_accuracy: 0.9609\n",
            "Epoch 49/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1465 - accuracy: 0.9466 - val_loss: 0.2512 - val_accuracy: 0.9609\n",
            "Epoch 50/200\n",
            "16/16 [==============================] - 0s 23ms/step - loss: 0.1233 - accuracy: 0.9457 - val_loss: 0.2486 - val_accuracy: 0.9531\n",
            "Epoch 51/200\n",
            "16/16 [==============================] - 0s 24ms/step - loss: 0.1346 - accuracy: 0.9519 - val_loss: 0.2640 - val_accuracy: 0.9453\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4d85d168d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJBXatmTEt7X",
        "outputId": "d7d1666a-f800-418b-e7c2-96026852337f"
      },
      "source": [
        "score=model.evaluate(x_test,y_test)\n",
        "print(score)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5/5 [==============================] - 0s 8ms/step - loss: 0.1466 - accuracy: 0.9750\n",
            "[0.14663314819335938, 0.9750000238418579]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dteBwMNrRKVR"
      },
      "source": [
        "saving the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhcSD74_VgT1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1358494-a4dd-4aa3-e99d-40536cb8f4e7"
      },
      "source": [
        "model.save(path)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: /content/assets\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cA1q9z6RVB0"
      },
      "source": [
        "Loading the Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNUAZowhRIrk"
      },
      "source": [
        "new_model=keras.models.load_model(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0OS5rqjRyTC",
        "outputId": "2ecc2e2e-3a79-446f-985c-faa65c7862a4"
      },
      "source": [
        "new_model.predict(x_valid[0].reshape(-1,30,30,1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.14540508, 0.62671316, 0.08857069, 0.13931102]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 266
        },
        "id": "Fe-yRo9jSUpF",
        "outputId": "b340d509-e4ee-427e-cae7-0c0745522312"
      },
      "source": [
        "plt.imshow(x_valid[0].reshape(30,30),cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}